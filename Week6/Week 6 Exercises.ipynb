{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39cb3029-ef1d-4c64-90ac-cd297c7893e8",
   "metadata": {},
   "source": [
    "# Weekly activities\n",
    "1. Apply custom sharpening kernel of aperture size 3 and 5 as shown below on 'native-bee.png':  \n",
    "$ 3 \\times 3$ kernel:  \n",
    "$ \\begin{bmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 5 & -1 \\\\\n",
    "0 & -1 & 0\\\\\n",
    "\\end{bmatrix}$  \n",
    "$ 5 \\times 5$ kernel:  \n",
    "$ \\begin{bmatrix}\n",
    "-1 & -1 & -1 & -1 & -1 \\\\\n",
    "-1 & -1 & -1 & -1 & -1 \\\\\n",
    "-1 & -1 & 25 & -1 & -1 \\\\\n",
    "-1 & -1 & -1 & -1 & -1 \\\\\n",
    "-1 & -1 & -1 & -1 & -1 \\\\\n",
    "\\end{bmatrix}$  \n",
    "What can you infer from the outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631c8d68-bc97-434d-aa98-58ba9510c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38fc2dcf-3947-41e5-9881-43abb7b02ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('images/native-bee.png')\n",
    "\n",
    "# Define the 3x3 sharpening kernel\n",
    "kernel_3x3 = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]])\n",
    "\n",
    "# Define the 5x5 sharpening kernel\n",
    "kernel_5x5 = np.array([\n",
    "    [-1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1],\n",
    "    [-1, -1, 25, -1, -1],\n",
    "    [-1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1]])\n",
    "\n",
    "sharpened_3x3 = cv.filter2D(image, -1, kernel_3x3)\n",
    "sharpened_5x5 = cv.filter2D(image, -1, kernel_5x5)\n",
    "\n",
    "cv.imshow('Original Image', image)\n",
    "cv.imshow('Sharpened with 3x3 Kernel', sharpened_3x3)\n",
    "cv.imshow('Sharpened with 5x5 Kernel', sharpened_5x5)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd05c57-2d05-46ba-a3eb-ccbba549f26e",
   "metadata": {},
   "source": [
    "$ 3 \\times 3$ kernel:\n",
    "Edges become more defined, and fine details more pronounced.The effect is moderate and preserves more of the image's natural appearance.\n",
    "\n",
    "$ 5 \\times 5$ kernel:\n",
    "This kernel much more aggressive in sharpening but resulting image is \"over-sharpened\" and introduce noise and exaggerated edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f899003-20ff-40cc-b61d-e474a49d24f9",
   "metadata": {},
   "source": [
    "2. Apply different image smoothing techniques (e.g. average filter, Gaussian kernel and median filter) on 'noise_lena.jpg' and display the resulting images after the convolution. Comment on the outcomes and deduce the type of noise present on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae2cd0f-a48e-4b5a-9507-6deb53b1de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('images/noise_lena.jpg')\n",
    "\n",
    "# Average filter\n",
    "average_filtered = cv.blur(image, (5, 5))\n",
    "\n",
    "# Gaussian filter\n",
    "gaussian_filtered = cv.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Median filter\n",
    "median_filtered = cv.medianBlur(image, 5)\n",
    "\n",
    "cv.imshow('Original Image', image)\n",
    "cv.imshow('Average Filtered', average_filtered)\n",
    "cv.imshow('Gaussian Filtered', gaussian_filtered)\n",
    "cv.imshow('Median Filtered', median_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94c39b-2a40-4f16-ba8a-bb243ebc9a19",
   "metadata": {},
   "source": [
    "Average Filter: The result blurred, seem less effective compare to other methods\n",
    "\n",
    "Gaussian Filter: The result more smoother and less blurry compared to average filter.\n",
    "\n",
    "Median Filter: The result have significantly reduced noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b05fd-a1c7-4bbc-9c71-01102020c00a",
   "metadata": {},
   "source": [
    "3. Write a program to *segment the boat and the people on it from the background*. Follow the instruction below:\n",
    "    - Use 'boat.jpg' as input.\n",
    "    - Apply Otsu thresholding.\n",
    "    - Draw bounding box to identify the region where the boat and people are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9111bab4-3eae-4b60-b43d-bf18fd7af444",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('images/boat.jpg')\n",
    "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Otsu's thresholding\n",
    "_, thresh_image = cv.threshold(gray_image, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv.findContours(thresh_image, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "largest_contour = max(contours, key=cv.contourArea)\n",
    "\n",
    "# Get the bounding box for the largest contour\n",
    "x, y, w, h = cv.boundingRect(largest_contour)\n",
    "\n",
    "# Create a mask from the thresholded image\n",
    "mask = np.zeros_like(image)\n",
    "mask[thresh_image == 255] = [255, 255, 255]\n",
    "\n",
    "# Use the mask to extract the color segmented region\n",
    "segmented_color_image = cv.bitwise_and(image, mask)\n",
    "\n",
    "# Draw the bounding box\n",
    "cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv.imshow('Original Image', image)\n",
    "cv.imshow('Thresholded Image', thresh_image)\n",
    "cv.imshow('Segmented Color Image', segmented_color_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
